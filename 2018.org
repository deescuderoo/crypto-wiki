#+TITLE: Papers from 2018
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP:  content
#+OPTIONS: toc:1 H:4 num:1

- [[wiki:index][Index]]
  
* [[https://eprint.iacr.org/2018/570][Fast Large-Scale Honest-Majority MPC for Malicious Adversaries (Koji Chida, Daniel Genkin, Koki Hamada, Dai Ikarashi, Ryo Kikuchi, Yehuda Lindell and Ariel Nof)]]
Presented at CRYPTO 2018 ([[https://youtu.be/AbX9Qm_OTe0][Video here]])

** Short Description
A compiler from secure-up-to-additive-attacks protocols to active security.

** Abstract
Protocols for secure multiparty computation enable a set of parties to
compute a function of their inputs without revealing anything but the
output. The security properties of the protocol must be pre- served in
the presence of adversarial behavior. The two classic adversary models
considered are semi-honest (where the adversary follows the protocol
specification but tries to learn more than allowed by examining the
protocol transcript) and malicious (where the adversary may follow any
arbitrary attack strategy). Protocols for semi-honest adversaries are
often far more efficient, but in many cases the security guarantees
are not strong enough.

In this paper, we present new protocols for securely computing any
functionality represented by an arithmetic circuit. We utilize a new
method for verifying that the adversary does not cheat, that yields a
cost of just twice that of semi-honest protocols in some settings. Our
protocols are information-theoretically secure in the presence of a
malicious adversaries, assuming an honest majority. We present
protocol variants for small and large fields, and show how to
efficiently instantiate them based on replicated secret sharing and
Shamir sharing. As with previous works in this area aiming to achieve
high efficiency, our protocol is secure with abort and does not
achieve fairness, meaning that the adversary may receive output while
the honest parties do not.

We implemented our protocol and ran experiments for different
numbers of parties, different network configurations and different
circuit depths.  Our protocol significantly outperforms the previous
best for this setting (Lindell and Nof, CCS 2017); for a large number
of parties, our implementation runs almost an order of magnitude
faster than theirs.

** My Summary
  
Some passively secure protocols in the honest majority setting are not so insecure as they seem: The only place in which an adversary may cheat is at the multiplication gates, and furthermore, the only thing it can do there is adding an error /independent of the inputs/ to the result of the multiplication.
This observation was made initially in [[[chida-1][1]]] and generalized in [[[chida-2][2]]].
Although the authors in [[[chida-1][1]]] already propose a compilation process from passive to active security, this work is the first concrete instantiation of the ideas presented in [[[chida-1][1]]] (TODO get the EXACT differences).

The authors propose a method to prevent additive attacks which essentially consists of secret-sharing each wire value $x$ as $([x],[r\cdot x])$ (where $[\cdot]$ is the underlying secret-sharing scheme used for the passively secure protocol), where $r\in\mathbb F$ is uniformly random, global and unknown to the adversary.
In addition, parties also have shares of $r$.

Let us denote the representation above by $\langle x\rangle$.
Addition gates can be processed easily.
To process the multiplication of to inputs $\langle x\rangle$ and $\langle y\rangle$, it suffices to use the passively secure multiplication protocol to compute $[z] = [x]\cdot [y]$ and $[r\cdot z] = [r\cdot x]\cdot [y]$ (notice that $[r\cdot y]$ is not used).

Recall that the adversary may introduce an additive error after each multiplication gate.
To ensure that the multiplication is correct, the parties open $r$ and multiply $[r\cdot y] = r\cdot [z], and check that this yields the same result as the one obtained above (by multiplying $[r\cdot x]$ and $[y]$).
Of course, opening $r$ can only be done if it is not going to be used anymore, i.e. right before the output gates (as a side note, one may try to keep $r$ shared and use the insecure multiplication protocol to get $[r\cdot z] = [r]\cdot [x]$, but I'm pretty sure this is not secure as the adversary can introduce an error that matches the previous one and thus it will remain undetected) .
Thus, one has to perform this check only at the end of the execution of the circuit.
Furthermore, instead of checking each intermediate multiplication individually, one can take a random linear combination of them and check this instead.

A final note is that this final check boils down to checking that a shared value is equal to zero.
However, this cannot be done by simply opening this value since, in the case that it is not equal to zero, this reveals sensitive information to the adversary.

Regarding numbers, the authors outperform what at that time was the best previous protocol for the same setting [[[chida-3][3]]].
The gap is significant for a large number of parties, with this protocol being around 10 times faster than the one from [[[chida-3][3]]].

*** References

1) <<chida-1>>D. Genkin, Y. Ishai, M. Prabhakaran, A. Sahai and E. Tromer. Circuits Resilient to Additive Attacks with Applications to Secure Computation. In STOC 2014.
2) <<chida-2>>D. Genkin, Y. Ishai and A. Polychroniadou. Efficient Multi-party Computation: From Passive to Active Security via Secure SIMD Circuits. In CRYPTO 2015.
3) <<chida-3>>Y. Lindell and A. Nof. A Framework for Constructing Fast MPC over Arithmetic Circuits with Malicious Adversaries and an Honest-Majority. In ACM CCS, 2017.
   
   
* [[https://eprint.iacr.org/2018/762][Generalizing the SPDZ Compiler For Other Protocols (Toshinori Araki and Assi Barak and Jun Furukawa and Marcel Keller and Yehuda Lindell and Kazuma Ohara and Hikaru Tsuchida)]]
Presented at CCS 2018 ([[https://www.youtube.com/watch?v%3D0mIqn8TqzmA][Video here]])

** Short Description
Compilation from high-level programs to MPC circuits

** Abstract
Protocols for secure multiparty computation (MPC) enable a set of mutually distrusting parties to compute an arbitrary function of their inputs while preserving basic security properties like privacy and correctness. The study of MPC was initiated in the 1980s where it was shown that any function can be securely computed, thus demonstrating the power of this notion. However, these proofs of feasibility were theoretical in nature and it is only recently that MPC protocols started to become efficient enough for use in practice. Today, we have protocols that can carry out large and complex computations in very reasonable time (and can even be very fast, depending on the computation and the setting). Despite this amazing progress, there is still a major obstacle to the adoption and use of MPC due to the huge expertise needed to design a specific MPC execution. In particular, the function to be computed needs to be represented as an appropriate Boolean or arithmetic circuit, and this requires very specific expertise. In order to overcome this, there has been considerable work on compilation of code to (typically) Boolean circuits. One work in this direction takes a different approach, and this is the SPDZ compiler (not to be confused with the SPDZ protocol) that takes high-level Python code and provides an MPC run-time environment for securely executing that code. The SPDZ compiler can deal with arithmetic and non-arithmetic operations and is extremely powerful. However, until now, the SPDZ compiler could only be used for the specific SPDZ family of protocols, making its general applicability and usefulness very limited. 

In this paper, we extend the SPDZ compiler so that it can work with general underlying protocols. Our SPDZ extensions were made in mind to enable the use of SPDZ for arbitrary protocols and to make it easy for others to integrate existing and new protocols. We integrated three different types of protocols, an honest-majority protocol for computing arithmetic circuits over a field (for any number of parties), a three-party honest majority protocol for computing arithmetic circuits over the ring of integers Z2n, and the multiparty BMR protocol for computing Boolean circuits. We show that a single high-level SPDZ-Python program can be executed using all of these underlying protocols (as well as the original SPDZ protocol), thereby making SPDZ a true general run-time MPC environment.In order to be able to handle both arithmetic and non-arithmetic operations, the SPDZ compiler relies on conversions from field elements to bits and back. However, these conversions do not apply to ring elements (in particular, they require element division), and we therefore introduce new bit decomposition and recomposition protocols for the ring over integers with replicated secret sharing. These conversions are of independent interest and utilize the structure of Z2n (which is much more amenable to bit decomposition than prime-order fields), and are thus much more efficient than all previous methods. We demonstrate our compiler extensions by running a complex SQL query and a decision tree evaluation over all protocols.

** My Summary
  
This work contains two major contributions.
The first one is concerned with the SPDZ compiler, which is the piece of the Bristol implementation of the SPDZ protocol ([[https://github.com/bristolcrypto/SPDZ-2][old repo]], now maintained as [[https://github.com/KULeuven-COSIC/SCALE-MAMBA][Scale-Mamba]]) that is in charge of taking a high-level description of the functionality to be computed and /compile/ it into a bytecode representation that can be run by the software.
This compiler is described in [[[araki-1][1]]].
What the authors of this work do is enhancing this tool to support other MPC protocols beyond SPDZ.
In particular, the protocols considered are the following:

1) The protocol from [[[araki-2][2]]]. Changes to the compiler are needed since this protocol doesn't use triples.
2) The protocol from [[[araki-3][3]],[[araki-4][4]]], instantiated over the ring $\mathbb{Z}_{2^k}$. This requires modifications to the basic set of primitives like secure comparison or bit decomposition.
3) The BMR protocol, where the main change arises from the fact that the protocol is fundamentally different to other secret-sharing-based protocols.

The second contribution of this work is precisely item 2 above, which is not really concerned with expanding the compiler itself but the virtual environment that executes the protocol, i.e. developing sub-protocols for specific tasks.
The challenge here is that, when working modulo $2^k$, secure comparisons or secure equality checks cannot be done as it is done over fields, which is already quite well studied.
The main reason for this is that you cannot divide by $2$ modulo $2^k$, and this (or a variation of this) is crucial in these other sub-protocols.
The authors here identify that if you have a bit-decomposition protocol (i.e. obtain shares of the bits of a given shared value) then all these sub-protocols can be easily implemented by running their respective circuits on the bits (for example, division by $2$ is simply a right shift).
In my opinion, this is not 100% true since many of these primitives could be computed more efficiently if one allows some form of preprocessing, as is the case with truncations, to cite an example (see the protocols by Catrina et al., for instance).
Furthermore, the bit-decomposition proposed by the authors itself can be made more efficient by allowing preprocessing, essentially by preprocessing some random shared bits, and also the bit-decomposition protocol is not actively secure.

However, although I believe that the bit-decomposition the authors propose is not the solution to /any/ basic primitive one may need, I do believe that this sub-protocol is very important and, moreover, the construction is really nice and makes explicit use of the fact that the computation is modulo a power of $2$ (and also that the protocol is based on replicated secret-sharing).
I will not discuss the details of the bit-decomposition protocol though.
# This makes use of the specifics of replicated secret sharing and the fact that the protocol has three parties.
I will just say that the protocol has the extremely important feature that the shares of the bits that are obtained are themselves bits, which is not something possible when working modulo a prime, where the shares of the bits are themselves field elements.
We exploit a similar feature in our S&P 2019 paper for the SPDZ2k protocol, and the effect of this is that whatever you use the shared bits for is going to be cheaper since your computation happens over bits.

A nice thing to explore is to get an actively secure version of the bit-decomposition protocol.
This may be easy since the protocol simply involves running certain circuit over some (binary) shares, which should be robust if the underlying additions and multiplications are robust (and multiplications can be made robust by preprocessing correct triples), but I'm not sure about this claim.

*** References

1) <<araki-1>>Marcel Keller, Peter Scholl, and Nigel P. Smart. An Architecture for Practical Actively Secure MPC With Dishonest Majority. In ACM CCS 2013.
2) <<araki-2>>Y. Lindell and A. Nof. A Framework for Constructing Fast MPC over Arithmetic Circuits with Malicious Adversaries and an Honest-Majority. In the 24th ACM CCS 2017.
3) <<araki-3>>T. Araki, A. Barak, J. Furukawa, T. Lichter, Y. Lindell, A. Nof, K. Ohara, A. Watzman and O. Weinstein. Optimized Honest-Majority MPC for Malicious Adversaries - Breaking the 1 Billion-Gate Per Second Barrier. In the 38th IEEE Symposium on Security and Privacy, 2017.
4) <<araki-4>>T. Araki, J. Furukawa, Y. Lindell, A. Nof and K. Ohara. High-Throughput Semi-Honest Secure Three-Party Computation with an Honest Majority. In the 23rd ACM CCS 2016.


   
   
      
      
      
      
      

* HyCC: Compilation of Hybrid Protocols for Practical Secure Computation
CCS 2018
** Short Description 
Optimizations for compiling high-level programs to MPC programs that combine airhtmetic and binary protocols.

** Abstract
While secure multi-party computation (MPC) is a vibrant research topic and a multitude of practical MPC applications have been presented recently, their development is still a tedious task that requires expert knowledge. Previous works have made first steps in compiling high-level descriptions from various source descriptions into MPC protocols, but only looked at a limited set of protocols. 

In this work we present HyCC, a tool-chain for automated compilation of ANSI C programs into hybrid protocols that efficiently and securely combine multiple MPC protocols with optimizing compilation, scheduling, and partitioning. As a result, our compiled protocols are able to achieve performance numbers that are comparable to hand-built solutions. For the MiniONN neural network (Liu et al., CCS 2017), our compiler improves performance of the resulting protocol by more than a factor of $3$. Thus, for the first time, highly efficient hybrid MPC becomes accessible for developers without cryptographic background.

** My Summary

In theory, a general-purpose MPC protocol can compute /any/ function.
However, for this to be meaningful in practice, one has to design a mechanism in which any given function can be ran securely by a given MPC protocol.
Furthermore, just like traditional compilers sometimes aim at improving efficiency by optimizing the program (e.g. preferring some instructions over others, eliminating dead code, etc.), it is desirable from an MPC compiler that it /automatically/ optimizes the given function so that the protocol execution can be as efficient as possible.

This work is concerned precisely with this. 
It presents a compiler that takes high-level programs written in C and compiles them into a description of a circuit which is more suitable for MPC protocols (in fact, it is directly compatible with ABY).
The salient feature of this compiler is that it optimizes the program so that the execution of the MPC protocol is as efficient as possible.
This is achieved partially by building on top of ShallowCC, which optimizes for depth (most MPC protocols get more expensive as the depth of the circuit grows).
However, the main contribution of this work is to optimize /protocol selection/, which is concerned with determining which type of protocol (either binary, arithmetic or Yao) is more suitable for a given part of the computation.

A high level overview of HyCC is the following.
First, a program written in ANSI-C is given.
Then, the following steps are executed (basically taken from the paper itself)

1) Automated Parallelization (§3.2.1): Automated identification of code blocks that can be evaluated in parallel using external tools.
2) Preprocessing, Lexing and Parsing (§3.2.2): Construction of an Abstract Syntax Tree (AST) from the input code.
3) Source Code Optimization and Loop Unrolling (§3.2.3): Source-to-source compilation using static analysis.
4) Code Decomposition (§3.2.4): Decomposition of the input program into multiple modules.
5) Circuit Compilation (§3.2.5): Compilation of each module in the different circuit representations.
6) Inter-Procedural Circuit Optimization (§3.2.6): Optimization of Boolean and arithmetic circuits across multiple modules.
7) Circuit Export (§3.2.7): Writing the decomposed circuit to a file, ready for reconstruction in protocol selection.

Step 4 consists of deciding which parts of the program can be considered as a "single-entity", so that the compiler can focus on optimizing them internally and also optimizing the relations among these.
HyCC separates modules by functions (each function is a module), loops, and arithmetic expressions.
Then, in step 5 these modules are compiled individually, and in step 6 these are optimized taking into account neighboring modules.

Finally, protocol selection in HyCC is a combination of scheduling heuristics (deciding which module to run in which order) and a "straight-forward combinatorial optimization approach by enumerating all possible protocol combinations using dynamic programming."

(TODO references)

A word of warning: As of today, 15-06-2019, there is no code available of this framework
